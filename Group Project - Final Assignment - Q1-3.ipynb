{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chinese-trading",
   "metadata": {},
   "source": [
    "# Cognitive Neuroscience: Group Project\n",
    "\n",
    "## Final Group Project Code Instructions\n",
    "\n",
    "Marijn van Wingerden, Department of Cognitive Science and Artificial Intelligence â€“ Tilburg University Academic Year 2020-2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baking-science",
   "metadata": {},
   "source": [
    "In this Jupyter Notebook, you will find the programmatic instructions to complete the Group Project. \n",
    "\n",
    "You will analyse a subset of the trials and conditions from the RITA dataset, as introduced by dr. Roncaglia in the second week of class. Your time-resolved analysis, using the FFT and baseline averaging, will be performed across ALL subjects in a group (Monolinguals, Early Learners, Late Learners) in the dataset, and look for oscillatory activity in relation to the onset of the **critical item** in each sentence (the auxilary verb).\n",
    "\n",
    "You will inspect activity in the following frequency bands:\n",
    "- Delta (1-4 Hz)\n",
    "- Theta (4-8 Hz)\n",
    "- Alpha (8-12 Hz)\n",
    "- Beta (15-25 Hz)\n",
    "- low Gamma (30-60 Hz)\n",
    "- high Gamma (60-100 Hz)\n",
    "(different cutoffs points can be found in the literature, we are sticking with these for convenience)\n",
    "\n",
    "All relevant methods have been covered in Worksheets 1-7, with the exception of loading multiple datafiles. Whenever a new method/function is introduced here, it will come with an example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-trouble",
   "metadata": {},
   "source": [
    "## Datafiles - assignment per group\n",
    "\n",
    "Each group will analyze one set of filler sentences (NA: Non-Ambiguous sentences) and a set of experimental sentences (AM: Ambiguous sentences). The conditions in the dataset are split over groups in the following way:\n",
    "\n",
    "- SF: subject-first\n",
    "- OF: object-first\n",
    "- IR: irregular rhythm\n",
    "- RR: regular rhythm\n",
    "\n",
    "- Monolinguals: RM\n",
    "    - Groups 01 + 02: SFIR triggers XX1 and XX5\n",
    "    - Groups 03 + 04: SFRR triggers XX2 and XX6\n",
    "    - Groups 05 + 06: OFIR triggers XX3 and XX7\n",
    "    - Groups 07 + 08: OFRR triggers XX4 and XX8\n",
    "- Early Learners: RB\n",
    "    - Groups 09 + 10: SFIR triggers XX1 and XX5\n",
    "    - Groups 11 + 12: SFRR triggers XX2 and XX6\n",
    "    - Groups 13 + 14: OFIR triggers XX3 and XX7\n",
    "    - Groups 15 + 16: OFRR triggers XX4 and XX8\n",
    "- Late Learners: RL\n",
    "    - Groups 17 + 18: SFIR triggers XX1 and XX5\n",
    "    - Groups 19 + 20: SFRR triggers XX2 and XX6\n",
    "    - Groups 21 + 22: OFIR triggers XX3 and XX7\n",
    "    - Groups 23 + 24: OFRR triggers XX4 and XX8\n",
    "\n",
    "- Odd groups:\n",
    "analyse the odd trials in the dataset\n",
    "- Even groups:\n",
    "analyse the even trials in the dataset\n",
    "\n",
    "You can download the datafiles from: https://surfdrive.surf.nl/files/index.php/s/JcA9speED020q4p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-armor",
   "metadata": {},
   "source": [
    "## Handing in of your code\n",
    "\n",
    "You can adapt this script template and hand it in as the code component of your Group Assignment Report.\n",
    "\n",
    "Whenever you are asked to make a plot, it should be completed with a meaningful plot title, xlabel and ylabel texts. Figures are started with a Matplotlib figure handle: \"fig_Q2A, ax = plt.subplots;\". This indicates that a link (called handle) to your figure will be saved in the variable, so we can easily check it when checking your scripts. Whenever a naming convention for a variable is given, use it, because it will allow semi-automatic grading of your project script.\n",
    "\n",
    "### Intermediate hand-in\n",
    "\n",
    "You will be able to hand in a script/notebook with your solutions to Q1-3 after the midterms, and the correct solution will be discussed in class to give you some feedback on how the Group Project is evaluated. Groups that do not hand in their solutions to Q1-3 will receive half of the total points available for these questions by default. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-banana",
   "metadata": {},
   "source": [
    "## Group members:\n",
    "\n",
    "Please list the contributors and their U-numbers here in comments:\n",
    "\n",
    "- u838557 | Vivienne Kraeter   \n",
    "- u133313 | Frederic Straub\n",
    "- u947993 | Jorge Horan-Barnes \n",
    "- u848541 | Tom de Beer\n",
    "- u551835 | Hamse Elmi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-spencer",
   "metadata": {},
   "source": [
    "## Setting up: list your modules to import\n",
    "For loading/saving puroposes, we will make use of the **os** package.\n",
    "An example worksheet with instructions on how to use the os package will be provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mexican-vacuum",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import scipy.io as spio\n",
    "import scipy.fft as fft\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reported-satellite",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "We will need to load the datafiles from all participants and add them all together so that we end up with a matrix that has nChannels x nTime x nParticipants (instead of trials). You can make your work easier by organising the datafiles in such a way that you put the control.npy files in their own subdirectory, and the experimental.npy files as well. \n",
    "\n",
    "In order to load the files, we can use the os package.\n",
    "\n",
    "Adapt the following so that it works on your machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "banner-south",
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "path_control = \"C:\\\\Users\\\\hamse\\\\OneDrive\\\\Documenten\\\\group_17\\\\Control\"\n",
    "path_experimental = \"C:\\\\Users\\\\hamse\\\\OneDrive\\\\Documenten\\\\group_17\\\\Experiment\"\n",
    "control_files = os.listdir(path_control)\n",
    "experimental_files = os.listdir(path_experimental)\n",
    "\n",
    "# check that the length of your files list matches the provided datafiles, and contains only .npy datafiles\n",
    "\n",
    "def checkLengthAndType(pathI):\n",
    "    count = 0\n",
    "    for path in os.listdir(pathI):\n",
    "        if os.path.isfile(os.path.join(pathI, path)) and path.endswith('.npy'):\n",
    "            count += 1\n",
    "    if(count==26):\n",
    "        return True\n",
    "    return False\n",
    "checkLengthAndType(path_control)\n",
    "checkLengthAndType(path_experimental)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-louisiana",
   "metadata": {},
   "source": [
    "## Combining data and matrix pre-allocation\n",
    "next, you will need to load these files one by one and extract the data for this participant. \n",
    "The data in the NumPy arrays are stored as Trials x Channels x Time. To aggregate across participants, you will thus need to add a 4th dimension to store the data.\n",
    "\n",
    "To be able to adequately pre-allocate the data from the different subjects, we will load one trial subject manually to have a look at the shape/dimensionality of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "artificial-dublin",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The amount of trials is equal to 22\nThe amount of channels is equal to either 64 or 65\nThe amount of samples/trace is equal to 751\n"
     ]
    }
   ],
   "source": [
    "EEG = np.load(os.path.join(path_control,control_files[0]))\n",
    "              \n",
    "# control_files is a list of strings, so indexing its first element returns a string\n",
    "# in this case, we are loading the first entry of control_files, i.e. participant 1\n",
    "\n",
    " \n",
    "\n",
    "# verify that the number of trials equals 22,\n",
    "if(EEG.shape[0]==22):\n",
    "    print(\"The amount of trials is equal to 22\")\n",
    "# verify that the number of channels equals 64 or 65 \n",
    "if(EEG.shape[1]==64 or EEG.shape(1)==65):\n",
    "    print(\"The amount of channels is equal to either 64 or 65\")\n",
    "# and verify that there are 751 samples per trace\n",
    "if(EEG.shape[2]==751):\n",
    "    print(\"The amount of samples/trace is equal to 751\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuck-extent",
   "metadata": {},
   "source": [
    "## Q1 - setting up the data structure and loading data from all participants\n",
    "\n",
    "The EEG data is currently stored as a 3-dimensional NumPy array. But to run our time-frequency analysis, we need some more information like the sampling rate and the time axis that corresponds to the stimulus-locked analysis window. In order to set up (=pre-allocate) a matrix that will hold all traces for all participants, we need to know the sizes of the dimensions of this 4-dimensional matrix, and fill up this matrix by looping over participants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "consolidated-tracy",
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-8bafdc6eea43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEEG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEEG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m                 \u001b[0mcomb_data_control\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparticipant\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEEG\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;31m#looping over experimental files to fill comb_data_experimental\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# There are 64 or 65 channels in the dataset. Only channels up to channel 59 are EEG channels\n",
    "# the remaining channels are EMG and EOG channels that we will ignore in this analysis\n",
    "# subset your EEG array so that only the EEG channels remain\n",
    "\n",
    "EEG = []\n",
    "# the channels above 59 are removed from the control dataset\n",
    "for x in range(0,len(control_files)):\n",
    "    EEG = np.load(os.path.join(path_control,control_files[x]))\n",
    "    EEG = EEG[:,:59,:]\n",
    "# the channels above 59 are removed from the experimental dataset\n",
    "for x in range(0,len(experimental_files)):\n",
    "    EEG = np.load(os.path.join(path_experimental,experimental_files[x]))\n",
    "    EEG = EEG[:,:59,:]\n",
    "\n",
    "# Define nTrials, nChan, nSamples and nPart. Then, pre-allocate a matrix\n",
    "# named comb_data, filled with zeros and with size nTrials, nChans x nSamples x nParticipants\n",
    "nTrials = 22\n",
    "nChans = 59 # number of channels\n",
    "nSamples = 751\n",
    "nParts = 26 # number of participants\n",
    "comb_data_control = np.zeros(shape=(nTrials,nChans,nSamples,nParts)) # 4 dimensional control-dataset array\n",
    "comb_data_experimental = np.zeros(shape=(nTrials,nChans,nSamples,nParts)) # 4 dimensional experimental-dataset array\n",
    "\n",
    "# next, we need to loop over all participant datafiles and add them to the appropriate slice in your 4-D array\n",
    "# For this, you need to use specific array indexing to indicate where in comb_data each participant's data\n",
    "# needs to go. You can and should reuse the data-reading code above.\n",
    "\n",
    "# loop over participants, and wihtin each iteration of the loop, load the\n",
    "# next datafile and fill comb_data with the EEG traces (nTrials x nChans x nSamples)\n",
    "# caution - multiple lines of code might be needed\n",
    "\n",
    "#looping over control files to fill comb_data_control\n",
    "for participant in range(len(control_files)):\n",
    "    for i in range(EEG.shape[0]):\n",
    "        for j in range(EEG.shape[1]):\n",
    "            for x in range(EEG.shape[2]):\n",
    "                comb_data_control[i,j,x,participant] = EEG[i,j,x]\n",
    "\n",
    "#looping over experimental files to fill comb_data_experimental\n",
    "for participant in range(len(experimental_files)):\n",
    "    for i in range(EEG.shape[0]):\n",
    "        for j in range(EEG.shape[1]):\n",
    "            for x in range(EEG.shape[2]):\n",
    "                comb_data_experimental[i,j,x,participant] = EEG[i,j,x]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-mainland",
   "metadata": {},
   "source": [
    "## Q2 - explore the data\n",
    "\n",
    "Let's explore this newly combined dataset a little bit. This sections fo EEG traces in your dataset have been taken with a [-0.5s, 1s] window aroun the relevant event. What's more, each trace has been averaged to its baseline period, so that the mean amplitude should be 0 (with some rounding error). \n",
    "\n",
    "To verify, first, determine the mean for the time period of -0.5 to 0 seconds. Given that the srate = 500 Hz, the baseline period corresponds to the first 250 samples\n",
    "- subset your combined data to only the first 250 samples\n",
    "- select a random participant and sunset the data further to only this participant\n",
    "- select a random EEG channel and subset the data further to only this channel\n",
    "\n",
    "This should leave you with a nTrials x 250 (samples) matrix. Create a similar evoked matrix with the remainder of the samples. With these matrices:\n",
    "- plot the traces for all trials in the **baseline** matrix (use transpose if necessary). \n",
    "- calculate the mean for each trace:\n",
    "    - once for the baseline period\n",
    "    - once for the remainder of the trial\n",
    "- plot these values (N= nTrials, check) in a histogram, each in their own subplot\n",
    "\n",
    "Refer to Worksheet 1 for example uses of **np.mean**. np.std works in a similar way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-beads",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_mean = ...\n",
    "evoked_mean = ...\n",
    "\n",
    "# now plot these three histograms using the subplot given\n",
    "fig_Q2A, ax = plt.subplots(figsize=(8,3), nrows=1, ncols=3) # 1x3 graph\n",
    "\n",
    "# plot the traces in ax[0]\n",
    "\n",
    "##\n",
    "## your code here\n",
    "##\n",
    "\n",
    "# plot the baseline mean in ax[1] with this code\n",
    "ax[1].hist(baseline_mean)\n",
    "plt.axes(ax[1])\n",
    "plt.title('Baseline means')\n",
    "ax[1].set_xlabel('Mean voltage')\n",
    "ax[1].set_ylabel('count')\n",
    "\n",
    "# plot the evoked mean in ax[2] with this code\n",
    "ax[2].hist(evoked_mean)\n",
    "plt.axes(ax[2])\n",
    "plt.title('Evoked means')\n",
    "ax[2].set_xlabel('Mean voltage')\n",
    "ax[2].set_ylabel('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "robust-international",
   "metadata": {},
   "source": [
    "Looking at theses histograms, you should see that the distribution of evoked mean values can vary: while EEG recordings are referenced to a common ground, and usualy then re-referenced to the global average, we are dealing here with specific cutouts of EEG traces around specific events in the dataset. The data has been normalised to the baseline window for each trial, but the mean of the evoked part is not controlled. In addition, there might be differences in the size of the amplitudes between channels and between participants due to differences in conductivity.\n",
    "\n",
    "Illustrate that this global averaging does not guarantee equal variance. Reuse the baseline and evoked subsets:\n",
    "- Compute, instead of the mean across samples, the standard deviation (numpy.std or variants)\n",
    "- calculate the mean for each trace:\n",
    "    - once for the baseline period\n",
    "    - once for the remainder of the trial\n",
    "- Adapt the plotting code for Q2A and plot these distributions of standard deviations in figure Q2B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demanding-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_std = ...\n",
    "evoked_std = ...\n",
    "\n",
    "fig_Q2B, ax = plt.subplots(figsize=(8,3), nrows=1, ncols=3) # don't forget proper plot annotation\n",
    "\n",
    "##\n",
    "## your code here\n",
    "##\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-lender",
   "metadata": {},
   "source": [
    "## Q3 - normalizing the data\n",
    "\n",
    "So, if there are large differences in mean and/or standard deviation between channels or participants, we can implement some standard scaling. First, let think about why this \"standard scaling\" (substracting the mean, dividing by std) is important? You will be combining data from different participants for these exercises. They have been possibly recorded at different days, with different gels or electrodes, and thus with different conductivity between participants. We will assume that the recording across videos within one participant remains stable. So, in order to compare and average the recordings from different participants \"fairly\", we want them to be on more or less the same scale.\n",
    "\n",
    "We can thus attempt to normalize the signal per participant, by dividing all data per participant by its standard deviation. Let's show the extent of the problem by plotting the participants with the lowest and highest std side by side. Re-create your matrix of std values for the evoked period, but:\n",
    "- do not subset one participant, but retain all participants (still only selecting 1 channel)\n",
    "- average the std values for each trace over trials, save in part_std (you will retain one value per participant)\n",
    "- use np.argmax (and variants) to create two indexes, min_std and max_std that point to the participants with the lowest and highest standard deviations\n",
    "- calculate and plot the average over trials for these two participants, using different line colors and proper line labeling. \n",
    "    - Plot them in the first subplot of a 1x2 subplot\n",
    "- Observe the scaling difference\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## your code here\n",
    "##\n",
    "\n",
    "part_std = \n",
    "min_std = \n",
    "max_std = \n",
    "\n",
    "fig_Q3, ax = plt.subplots(figsize=(8,3), ...) # don't forget proper plot annotation\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roman-chain",
   "metadata": {},
   "source": [
    "Next, we want to use the standard deviation for each channel to normalize (i.e. divide) the data by this value. \n",
    "- Re-use the standard deviation per participants calculated above\n",
    "- Normalize the evoked matrix (per participant) by the participant std (save as evoked_norm)\n",
    "- plot the **normalized** average over trials for these two participants, using different line colors and proper line labeling. \n",
    "    - Plot them in the second subplot of fig Q3\n",
    "    - The data should now be more or less on the same scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-committee",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## your code here\n",
    "##\n",
    "\n",
    "evoked_norm = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-compact",
   "metadata": {},
   "source": [
    "We now have to apply this normalization across all channels. The fairest way is to calculate the grand standard deviation per participant (over all their channels, so the relative scaling between channels remains intact). This will normalize the range of the signal within one participants, so that they will be comparable between participants.\n",
    "\n",
    "In order to do this: \n",
    "- first preallocate a normalized matrix with the same size as comb_data, called comb_data_norm.\n",
    "- Next, create a loop to go over Participants, and inside the loop:\n",
    "    - calculate the grand standard deviation per participant \n",
    "    - normalization all values by this grand standard deviation\n",
    "        - Examine the numpy.std documentation to get a single std value across a 3D matrix\n",
    "- Then, recreate the plot with the trial averages as made for the first subplot of fig_Q2\n",
    "    - It should now rather resemble the normalized plot as made in the second subplot\n",
    "- Save this figure as Figure1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-hormone",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## your code here\n",
    "##\n",
    "\n",
    "comb_data_norm = ...\n",
    "\n",
    "for \n",
    "    ..\n",
    "end\n",
    "\n",
    "\n",
    "fig_Q3, ax = plt.subplots(figsize=(8,3), ...) # 1x1 fig, don't forget proper plot annotation\n",
    "...\n",
    "\n",
    "# save Figure Q3C as your Figure 1 for your report\n",
    "Figure1 = fig_Q3;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd068f960c3fbf659dbf9b73299d7cb0795a5a8db53af9dbc6f936901bf2358cd34",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}